{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas default rows/columns for better visualization\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_rows(df, column, invalid_values):\n",
    "    \"\"\"\n",
    "    Remove rows with invalid values in a specified column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        column (str): The column to check for invalid values.\n",
    "        invalid_values (list): List of values to be removed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataframe.\n",
    "    \"\"\"\n",
    "    return df[~df[column].isin(invalid_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    \"\"\"\n",
    "    Clean column names by removing numbers and trailing decimals.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with cleaned column names.\n",
    "    \"\"\"\n",
    "    df.columns = [re.sub(r'^\\s*\\d+:', '', re.sub(r'\\.\\d+\\s*$', '', col)) for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cleaning(df):\n",
    "    \"\"\"\n",
    "    Perform initial data processing on the dataframe.\n",
    "\n",
    "    Steps:\n",
    "    - Remove rows after the first occurrence of \"{ñ class}\" in the \"Capital\" column.\n",
    "    - Adjust misaligned top row.\n",
    "    - Remove rows with invalid or total values.\n",
    "    - Convert \"NaN\" strings to actual NaN values.\n",
    "    - Fill missing values in the \"Capital\" column.\n",
    "    - Extract only the capital name, removing preceding text.\n",
    "    - Drop columns containing \"Total\" or \"Ignored\".\n",
    "    - Clean column names.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed dataframe.\n",
    "    \"\"\"\n",
    "    first_invalid_index = df[df['Capital'] == \"{ñ class}\"].index[0]\n",
    "    \n",
    "    df = df.iloc[:first_invalid_index].copy()\n",
    "\n",
    "    df.iloc[0, 1:] = df.iloc[0, :-1].values\n",
    "\n",
    "    df = remove_invalid_rows(df, ' Faixa Remun Média (SM)', ['{ñ class}']) \n",
    "    \n",
    "    df = df.replace(\"NaN\", np.nan)\n",
    "    \n",
    "    df['Capital'] = df['Capital'].ffill()\n",
    "    \n",
    "    # Ensure 'Capital' is treated as string before using .str methods\n",
    "    df['Capital'] = df['Capital'].str.split(':').str[1]\n",
    "\n",
    "    df = remove_invalid_rows(df, ' Faixa Remun Média (SM)', ['Total']) \n",
    "    \n",
    "    df = df.drop(columns=df.filter(like='Total').columns, errors='ignore')\n",
    "    df = df.drop(columns=df.filter(like='Ignorado').columns, errors='ignore')\n",
    "    \n",
    "    df = clean_column_names(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gender_df(df, year, gender):\n",
    "    \"\"\"\n",
    "    Create a dataframe filtered by gender, keeping relevant columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        year (int): The year to be added to the dataframe.\n",
    "        gender (str): Gender keyword to filter columns (\"Masculino\" or \"Feminino\").\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered and cleaned dataframe for the specified gender.\n",
    "    \"\"\"\n",
    "    gender_cols = ['Capital', ' Faixa Remun Média (SM)'] + [col for col in df.columns if gender in col]\n",
    "    df_gender = df[gender_cols]\n",
    "    df_gender.iloc[0, 0] = \"capital\"\n",
    "    df_gender.iloc[0, 1] = \"faixa_remuneracao_media_sm\"\n",
    "    \n",
    "    # Set first row as header\n",
    "    new_header = df_gender.iloc[0]\n",
    "    df_gender = df_gender[1:]\n",
    "    df_gender.columns = new_header \n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    df_gender = df_gender.loc[:, ~df_gender.columns.duplicated()]\n",
    "    df_gender[\"sexo\"] = \"M\" if gender == \"Masculino\" else \"F\"\n",
    "    df_gender[\"ano\"] = year\n",
    "    \n",
    "    # Clean column names\n",
    "    df_gender = clean_column_names(df_gender)\n",
    "    \n",
    "    # Remove columns containing \"Total\" or \"{ñ class}\"\n",
    "    df_gender = df_gender.drop(columns=df_gender.filter(like='Total').columns, errors='ignore')\n",
    "    df_gender = df_gender.drop(columns=df_gender.filter(like='{ñ class}').columns, errors='ignore')\n",
    "    \n",
    "    return df_gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_adjustments(df_final, cols_exclude = ['faixa_remuneracao_media_sm', 'capital', 'sexo', 'ano']):\n",
    "    \"\"\"\n",
    "        Perform final adjustments to the processed dataframe, including formatting and type conversion.\n",
    "\n",
    "        Steps:\n",
    "        - Remove unwanted columns.\n",
    "        - Normalize text format (lowercase, replace spaces and special characters).\n",
    "        - Convert numerical columns to integer format.\n",
    "\n",
    "        Args:\n",
    "            df_final (pd.DataFrame): The dataframe to be adjusted.\n",
    "            cols_exclude (list): List of columns to exclude from numeric conversion.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The adjusted dataframe.\n",
    "        \"\"\"\n",
    "\n",
    "    # adjust the columns typing and content\n",
    "    df_final = df_final.drop(columns=df_final.filter(like='{ñ class}').columns, errors='ignore')\n",
    "    df_final['faixa_remuneracao_media_sm'] = df_final['faixa_remuneracao_media_sm'].apply(lambda x: unidecode(str(x)))\n",
    "    df_final['capital'] = df_final['capital'].apply(lambda x: unidecode(str(x)))\n",
    "    df_final['faixa_remuneracao_media_sm'] = df_final['faixa_remuneracao_media_sm'].str.replace(' ', '_')\n",
    "    df_final['capital'] = df_final['capital'].str.replace('-', '_').str.replace(' ', '_')\n",
    "    df_final['faixa_remuneracao_media_sm'] = df_final['faixa_remuneracao_media_sm'].str.lower()\n",
    "    df_final['capital'] = df_final['capital'].str.lower()\n",
    "    \n",
    "\n",
    "\n",
    "    # adjust relevant columns content to int type\n",
    "    for col in df_final.columns:\n",
    "        if col not in cols_exclude:\n",
    "            df_final[col] = df_final[col].astype(str).str.replace('.', '')\n",
    "            df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    #Extract capital code to dataframe\n",
    "    # Ensure capital column is string before applying transformations\n",
    "    df_final['capital'] = df_final['capital'].astype(str)\n",
    "    # Extract capital code ensuring robustness\n",
    "    df_final[['capital', 'capital_code']] = df_final['capital'].str.extract(r'^(.*?)_{1,}([a-zA-Z]+)$', expand=True)\n",
    "\n",
    "    # Extract sm_code by keeping only the first numeric value in the salary range\n",
    "    df_final['sm_code'] = df_final['faixa_remuneracao_media_sm'].str.extract(r'(\\d+)')\n",
    "    df_final['sm_code'] = pd.to_numeric(df_final['sm_code'], errors='coerce').fillna(0).astype(int)\n",
    "    # Keep only the portion of 'faixa_remuneracao_media_sm' after the colon\n",
    "    df_final['faixa_remuneracao_media_sm'] = df_final['faixa_remuneracao_media_sm'].str.split(':').str[-1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: /Users/bolsolui/Library/CloudStorage/OneDrive-adidas/Documents/personal/github/forecasting_rais_data/pipeline/files\n",
      "Processing directory: /Users/bolsolui/Library/CloudStorage/OneDrive-adidas/Documents/personal/github/forecasting_rais_data/pipeline/files/categoria\n",
      "Processing file: cnae_2018.csv\n",
      "Processing file: cnae_2019.csv\n",
      "Processing file: cnae_2009.csv\n",
      "Processing file: cnae_2021.csv\n",
      "Processing file: cnae_2020.csv\n",
      "Processing file: cnae_2008.csv\n",
      "Processing file: cnae_2011.csv\n",
      "Processing file: cnae_2010.csv\n",
      "Processing file: cnae_2006.csv\n",
      "Processing file: cnae_2012.csv\n",
      "Processing file: cnae_2013.csv\n",
      "Processing file: cnae_2007.csv\n",
      "Processing file: cnae_2017.csv\n",
      "Processing file: cnae_2016.csv\n",
      "Processing file: cnae_2014.csv\n",
      "Processing file: cnae_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/98kf6nzs505d1y91nml4ff2wzx529r/T/ipykernel_13903/932063405.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[['capital', 'capital_code']] = df_final['capital'].str.extract(r'^(.*?)_{1,}([a-zA-Z]+)$', expand=True)\n",
      "/var/folders/7z/98kf6nzs505d1y91nml4ff2wzx529r/T/ipykernel_13903/932063405.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['sm_code'] = df_final['faixa_remuneracao_media_sm'].str.extract(r'(\\d+)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final file: cnae.csv\n",
      "Processing completed for: cnae\n",
      "Processing directory: /Users/bolsolui/Library/CloudStorage/OneDrive-adidas/Documents/personal/github/forecasting_rais_data/pipeline/files/escolaridade\n",
      "Processing file: escolaridade_2017.csv\n",
      "Processing file: escolaridade_2016.csv\n",
      "Processing file: escolaridade_2014.csv\n",
      "Processing file: escolaridade_2015.csv\n",
      "Processing file: escolaridade_2011.csv\n",
      "Processing file: escolaridade_2010.csv\n",
      "Processing file: escolaridade_2006.csv\n",
      "Processing file: escolaridade_2012.csv\n",
      "Processing file: escolaridade_2013.csv\n",
      "Processing file: escolaridade_2007.csv\n",
      "Processing file: escolaridade_2009.csv\n",
      "Processing file: escolaridade_2021.csv\n",
      "Processing file: escolaridade_2020.csv\n",
      "Processing file: escolaridade_2008.csv\n",
      "Processing file: escolaridade_2018.csv\n",
      "Processing file: escolaridade_2019.csv\n",
      "Saving final file: escolaridade.csv\n",
      "Processing completed for: escolaridade\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, the script locates the folders containing the necessary files, applies all required data transformations, and consolidates the processed information into a single file per year. This final dataset serves as the foundation for the subsequent phases of the project.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # find all the files to loop\n",
    "    current_dir = os.getcwd()\n",
    "    base_dir = os.path.dirname(current_dir)  # Moves up one level\n",
    "    files_dir = os.path.join(base_dir, \"files\") \n",
    "\n",
    "    if not files_dir:\n",
    "        print(\"Error: 'files' directory not found.\")\n",
    "\n",
    "    # loop through every file in directory\n",
    "    for root, dirs, files in os.walk(files_dir):\n",
    "        final_file_name = \"\"\n",
    "        df_final = pd.DataFrame()\n",
    "        print(f\"Processing directory: {root}\")\n",
    "        os.chdir(root)\n",
    "        files_csv = glob.glob(\"*.csv\")\n",
    "        \n",
    "        if files_csv:\n",
    "            for file in files_csv:\n",
    "                print(f\"Processing file: {file}\")\n",
    "\n",
    "                # retrieve filename and infer the year from it\n",
    "                final_file_name = re.search(r'^[^0-9]+', file).group().rstrip('_')\n",
    "                year = re.search(r'\\d{4}', file).group()\n",
    "\n",
    "                # process the file: read, clean, adjust by gender\n",
    "                df = pd.read_csv(file, sep=\";\", encoding='latin-1', skiprows=1, header=[0])\n",
    "                df = initial_cleaning(df)\n",
    "                df_female = create_gender_df(df, year, \"Feminino\")\n",
    "                df_male = create_gender_df(df, year, \"Masculino\")\n",
    "                df_final = pd.concat([df_final, df_female, df_male])\n",
    "                \n",
    "            # final adjustments\n",
    "            df_final = final_adjustments(df_final)\n",
    "            \n",
    "            print(f\"Saving final file: {final_file_name}.csv\")\n",
    "            df_final.to_csv(f'{final_file_name}.csv', index=False)\n",
    "            print(f\"Processing completed for: {final_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
